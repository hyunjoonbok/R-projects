---
title: "Simple Basket Analysis - ALU Titles"
date: "May 1, 2020"
output: pdf_document
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[width=2in,height=2in]{Picture1.png}\LARGE\\}
  - \posttitle{\end{center}}
---
---

```{r setup, include=FALSE}
library(arules)
library(arulesViz)
library(tidyverse)
library(readxl)
library(knitr)
library(lubridate)
library(RColorBrewer)
library(reactable)
library(plyr)
library(data.table)
library(ggplot2)
library(stringr)
library(DT)
library(visNetwork)
library(igraph)
library(kableExtra)

# Set working directory
setwd("C:/Users/bokhy/Desktop/ATG")

# Read data
prod <- read.csv("Production Arcade Logs_new.csv")
```

```{r, include=FALSE}
# Adding "service" column
prod <- prod %>% filter(!activity.platform == "AddOn")
prod$activity.game_id <- as.numeric(prod$activity.game_id)

prod <- prod %>%
  mutate(
    service = case_when(
      activity.game_id < 10000 ~ 'Built-in 350',
      activity.game_id < 10000000 ~ 'BYOG',
      activity.game_id >= 10000000 ~ 'ArcadeNet',
      TRUE ~ 'NA'
    )
  )

prod$activity.platform <- as.character(prod$activity.platform)
prod$service <- as.character(prod$service)

prod$activity.platform <- ifelse(prod$activity.platform == "", prod$service,prod$activity.platform)

prod$activity.platform[prod$activity.platform == 'BuildIn'] <- 'Built-in 350'
prod$activity.platform[prod$activity.platform == 'Byog'] <- 'BYOG'

prod <- prod %>% 
  filter(!activity.platform =='America/Chicago') %>% 
  filter(!activity.platform =='America/Phoenix')
```
# **Abstract**

> Problem: While we may know that certain titles are frequently played together, we wasn't able to clearly uncover these associations

> Purpose: In order to see the combinations of games that tend to be played at same time or consevutively. Then, we can ‘recommend’ a list of titles for customers based on what they have already played or are about to play

> Data Extracted Period : Oct.22.2019 - Apr.27.2020 (189 days)

> Condition: BYOG / Add-on titles are excluded


## **Raw data**

#### Number of logs recorded per service 
```{r}
table(prod$activity.platform)
```

```{r ,include=FALSE}
prod$activity.platform <- as.factor(prod$activity.platform)
prod <- prod %>% separate(X.NAME.,
                          c("Date","a"), sep = '@')

prod$Time <- gsub("\\..*","",prod$a)

prod$Date <- as.Date(prod$Date, "%B %d, %Y")

prod$Weekdays <- weekdays(prod$Date)

prod$hour <- as.numeric(gsub("\\:.*$", "", prod$Time))
prod$timeoftheday<- with(prod, ifelse(hour >= 5 & hour<=11, "morning",
                                      ifelse(hour>11 & hour<=16, "afternoon",
                                             ifelse(hour>16 & hour<=21, "evening" ,"night"))))
prod$a <- NULL
prod <- prod %>% select(Date,Time,Weekdays,hour,timeoftheday, everything())


positions <- c("Built-in 350", "ArcadeNet")
prod <- prod %>% 
  mutate(Game = as.factor(activity.game_title)) %>% 
  mutate(State = as.factor(geoip.region_name)) %>% 
  mutate(Platform = as.factor(activity.platform)) %>% 
  mutate(Email = as.factor(account.email)) %>% 
  mutate(hour = as.factor(hour)) %>%
  mutate(timeoftheday = as.factor(timeoftheday)) %>%
  filter(Platform %in% positions) %>% 
  filter(Game != "") %>% 
  filter(Email != "") %>% 
  filter(!grepl('pc',Game, ignore.case = TRUE)) %>% 
  filter(!grepl('desk',Game, ignore.case = TRUE)) %>% 
  filter(!grepl('laptop',Game, ignore.case = TRUE)) %>%
  filter(!grepl('coin',Game, ignore.case = TRUE))  %>%
  filter(!grepl('Steam',Game, ignore.case = TRUE))  %>%
  filter(!grepl('battlenet',Game, ignore.case = TRUE)) %>%
  filter(!grepl('BYOG',Game, ignore.case = TRUE)) %>%
  filter(!grepl('origin',Game, ignore.case = TRUE)) %>%
  filter(!grepl('uplay',Game, ignore.case = TRUE)) 


prod$Game <- as.character(prod$Game)
prod$Game[prod$Game == "Fix-It Felix, Jr."] <- "Fix-It Felix Jr."
prod$Game <- as.factor(prod$Game) 

prod <- prod %>% filter(grepl("@",Email))
prod <- prod %>% filter(!grepl(":",Email))

prod <- prod %>% select(Date, Email, Game, State, Platform)
```

## **Processed Data** 
```{r}
kable(head(prod,8), caption = "An example of Processed data")
```

```{r, include=FALSE, , warning=FALSE}
# combine all products from one e-mail and date into one row 
transactionData <- ddply(prod,c("Email","Date"), 
                         function(df1)paste(df1$Game,collapse = ","))  
# not-using columns
transactionData$Email <- NULL
transactionData$Date <- NULL

#Rename column to items
colnames(transactionData) <- c("items")

# Set working directory
setwd("C:/Users/bokhy/Desktop/ATG")

# Save and read the file
write.csv(transactionData,"market_basket_transactions.csv", quote = FALSE, row.names = FALSE)
tr <- read.transactions('market_basket_transactions.csv', rm.duplicates= TRUE, format = 'basket', sep=',', cols = NULL, skip = 1)
tr@itemInfo$labels <- gsub("\"","",tr@itemInfo$labels)
```


```{r, include=FALSE}
# inspect(tr[1:10])
# Density tells the percentage of non-zero cells in a sparse matrix
# 22191x7876x0.001930725 (density)
```


## **Popular titles**
```{r}
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), 
                  main="Item Frequency Plot")
```

### - Centiple / Burgertime / Fix-it-Felix.Jr seems to appear most times.

\newpage

# **Association Rules Algorithm**

#### Glossary Definition 

> LHS: Antecedent (IF part)

> RHS: Consequent (THEN part)

> Support: The fraction of which each item set occurs.

> Confidence: probability/likeliness of occurrence that RHS would happen for LHS.

> Lift: The ratio by which by the confidence of a rule exceeds the expected confidence.

> Count: The actual data count that supports certain rule


```{r, include=FALSE}
summary(tr)
```
#### Parameter Setting
> Minimum support : 0.001 (0.1%)

> Minimum Confidence: 0.8 (80%)

> Maximum number of items: 5

```{r, include=FALSE}
# Association Setting
association.rules <- apriori(tr, parameter = list(supp = 0.001, conf = 0.8, maxlen = 8))
# Remove redundant rule    
association.rules <- association.rules[!is.redundant(association.rules)]
# Sort by "most likly" rules
association.rules <- sort(association.rules, by = "confidence", decreasing = TRUE)
```

```{r}
write(association.rules,
      file = "association_rules.csv",
      sep = ",",
      quote = TRUE,
      row.names = FALSE)

# Make pretty table
association_data <- read.csv('association_rules.csv')
```




# **Top 5 Rules (by confidence)**
```{r}
inspect(association.rules[1:5])
```

### - For example, when users played "Brain Game (2600)", it's 100% likely that the user play "Fix-it-Felix" right after it, because the confidence is 1

### - Also, "Brain Game (2600)" and "Fix-it-Felix" are "9x more likely" to be played together than played separately, because the lift is around 9

### - "The Cliffhanger" and "Edward Randy" are 100% likely to be played consecutively, 81 times more likely to be played together than played separately, and 49 users actaully played it together


# **Targeting Titles (example)**

## (1) What games are played 'before' Centipede?
```{r, include=FALSE}
association.rules_sample1 <- apriori(tr, parameter = list(supp = 0.001, conf = 0.8),appearance = list(default = "lhs",rhs = "Centipede¢ç (Arcade)"))
```
```{r}
inspect(head(association.rules_sample1))
```

### - Per 2nd rule above, for users who played "Centipede", they are 100% likely to have played "Fix-It Felix Jr." and "Super Baseball(2600)" right before they played "Centipede"

### - Also,both are "5.6 times more likely"" to be played together than played separately, because the lift is 5.6




## (2) Customers who played Fix-It Felix Jr. also played... 
```{r, include=FALSE}
# Set a minimum length of 2 to avoid empty left hand side items
association.rules_sample2 <- apriori(tr, parameter = list(supp = 0.001, conf = 0.1, maxlen = 2),appearance = list(lhs = "Fix-It Felix Jr.",default = "rhs"))
association.rules_sample2 <- sort(association.rules_sample2, by = "confidence", decreasing = TRUE)
```
```{r}
inspect(head(association.rules_sample2))
```

### - Users who played "Fix-It Felix Jr." are 23% more likely to play "Centipede" right after

### - "Fix-It Felix Jr." and "Centipede" are 1.3 times more likely to be played together and 102 users have actaully played consecutively (count = 102)

\newpage

# Appendix

> Apriori Algorithm		
> Candidate itemsets are generated using only the large itemsets of the previous pass without considering the transactions in the database.

> The large itemset of the previous pass is joined with itself to generate all itemsets whose size is higher by 1.

> Each generated itemset that has a subset which is not large is deleted. The remaining itemsets are the candidate ones.


```{r eval=FALSE, include=FALSE}
# Visualization
# Filter rules with confidence greater than 0.5 or 50%
subRules <- association.rules[quality(association.rules)$confidence>0.5]

# 0.
#plot(association.rules, method = "grouped", control = list(k = 5))
plot(association.rules, method="graph", control=list(type="items"))
#plot(association.rules, method="paracoord",  control=list(alpha=.5, reorder=TRUE))
#plot(association.rules,measure=c("support","lift"),shading="confidence",interactive=T)

# 1.
#plotly_arules(subRules)

# 2. 
# Select 10 rules from subRules having the highest confidence.
subrules2 <- head(sort(association.rules, by="confidence"),20)
ig <- plot( subrules2, method="graph", control=list(type="items") )

ig_df <- toVisNetworkData(ig, idToLabel = FALSE)

visNetwork(ig_df$nodes, ig_df$edges) %>%
  visNodes(size = 10) %>%
  visLegend() %>%
  visEdges(smooth = FALSE) %>% 
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%
  visInteraction(navigationButtons = TRUE) %>%
  visEdges(arrows = 'from') %>%
  visPhysics(
    solver = "barnesHut",
    maxVelocity = 35,
    forceAtlas2Based = list(gravitationalConstant = -6000))
# 3. 
# As mentioned above, the RHS is the Consequent or the item we propose the customer will buy; 
# the positions are in the LHS where 2 is the most recent addition to our basket 
# and 1 is the item we previously had.
# Filter top 20 rules with highest lift
subRules2<-head(subRules, n=20, by="lift")
plot(subRules2, method="paracoord")


# Save graph. For example, the 1000 rules with the highest lift are exported by:
#saveAsGraph(head(subRules, n = 1000, by = "lift"), file = "rules.graphml")
```
